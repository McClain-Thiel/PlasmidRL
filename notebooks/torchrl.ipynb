{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938cdb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 09-15 13:57:28 [__init__.py:216] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs.llm import ChatEnv\n",
    "from torchrl.envs import Transform\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from dotenv import load_dotenv\n",
    "import httpx\n",
    "import os\n",
    "import warnings\n",
    "import asyncio\n",
    "from typing import Optional, List, Dict, Tuple\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import httpx\n",
    "import torch\n",
    "import tensordict\n",
    "from tensordict import TensorDict\n",
    "from torchrl.data.tensor_specs import CompositeSpec, Unbounded\n",
    "\n",
    "from torchrl.modules.llm import TransformersWrapper\n",
    "from torchrl.collectors.llm import LLMCollector\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "tensordict.set_list_to_stack(True).set() \n",
    "\n",
    "model = \"McClain/plasmidgpt-addgene-gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2e14d-78f0-495c-a7ba-5f1ad676e049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if docker server is up\n",
    "import requests\n",
    "r = requests.get(\"http://server:8080/health\")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9d30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model, token=os.getenv(\"HF_TOKEN\"))\n",
    "model = AutoModelForCausalLM.from_pretrained(model,  token=os.getenv(\"HF_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8b1e1f79-f472-4c61-8d4e-8d18659dddc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = ChatEnv(\n",
    "    input_mode=\"text\",\n",
    "    batch_size=(1,),\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4594cc4-0264-4649-837f-df79f00095dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        query: NonTensorStack(\n",
      "            ['AATG'],\n",
      "            batch_size=torch.Size([1]),\n",
      "            device=None),\n",
      "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        text: Text(\n",
      "            prompt=NonTensorStack(\n",
      "                ['    <|im_start|>user\\nAATG<|im_end|>\\n<|im_start...,\n",
      "                batch_size=torch.Size([1]),\n",
      "                device=None),\n",
      "            response=None,\n",
      "            full=None,\n",
      "            batch_size=torch.Size([1]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([1]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "reset = env.reset(\n",
    "        TensorDict(\n",
    "            {\"query\": [\"AATG\"]},\n",
    "            batch_size=(1,),\n",
    "    )\n",
    ")\n",
    "print(reset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c31b4ff-9168-4f91-936b-18624cc22069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        text: Text(\n",
       "            full=NonTensorData(data=a string, batch_size=torch.Size([1]), device=None),\n",
       "            prompt=None,\n",
       "            response=None,\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand = env.rand_action()\n",
    "rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88828e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardTransform(Transform):\n",
    "    \"\"\"Assign rewards by calling external scoring endpoints in parallel.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        rewards_server_url: Optional[str] = \"http://localhost:8080\",\n",
    "        timeout_s: float = 60.0,\n",
    "    ):\n",
    "        super().__init__(in_keys=[], out_keys=[\"reward\"])\n",
    "\n",
    "        self.rewards_server_url = rewards_server_url.rstrip(\"/\")\n",
    "        self.client = httpx.AsyncClient(\n",
    "            base_url=self.rewards_server_url,\n",
    "            timeout=httpx.Timeout(timeout_s),\n",
    "            follow_redirects=True,\n",
    "        )\n",
    "        #defaults for evaluating plasmif \n",
    "        self.require = {\"ori\": None, \"amr\": None, \"mcs\": True, \"promoter\": None}\n",
    "        self.weights = {\"ori\": 0.30, \"amr\": 0.30, \"mcs\": 0.20, \"promoter\": 0.20}\n",
    "        self.gc = {\"target\": 0.55, \"weight\": 0.05, \"tolerance\": 0.10}\n",
    "        self._test_connection()\n",
    "\n",
    "        # Exact paths & params per your curl commands\n",
    "        self._endpoints: List[Dict] = [\n",
    "            {\"name\": \"amrfinder\", \"path\": \"/amrfinder/text\", \"params\": {\"is_protein\": \"false\", \"format\": \"json\"}},\n",
    "            {\"name\": \"prodigal\",  \"path\": \"/prodigal/text\",  \"params\": {\"mode\": \"auto\",   \"format\": \"json\"}},\n",
    "            {\"name\": \"plannotate\",\"path\": \"/plannotate/fast\",\"params\": {}},\n",
    "        ]\n",
    "\n",
    "        # Plain text in, accept json or text back\n",
    "        self._headers = {\n",
    "            \"Content-Type\": \"text/plain; charset=utf-8\",\n",
    "            \"Accept\": \"application/json, text/plain; q=0.9, */*; q=0.1\",\n",
    "        }\n",
    "\n",
    "    def _test_connection(self):\n",
    "        import requests\n",
    "        try:\n",
    "            r = requests.get(self.rewards_server_url + \"/health\", timeout=5)\n",
    "            r.raise_for_status()\n",
    "        except requests.RequestException as e:\n",
    "            raise RuntimeError(f\"Failed to connect to rewards server: {e}\")\n",
    "\n",
    "    async def _post_text(self, path: str, params: Dict, text: str, name: str) -> Tuple[bool, Dict]:\n",
    "        try:\n",
    "            resp = await self.client.post(\n",
    "                path, params=params, content=text.encode(\"utf-8\"), headers=self._headers\n",
    "            )\n",
    "            ok = (resp.status_code == 200)\n",
    "            if not ok:\n",
    "                try:\n",
    "                    preview = (resp.text or \"\")[:300]\n",
    "                except Exception:\n",
    "                    preview = \"<unreadable>\"\n",
    "                print(f\"[{name}] {path} -> {resp.status_code} | {preview}\")\n",
    "            return {\"status\": ok, \"name\": name, \"reponse\": resp.json()}\n",
    "        except Exception as e:\n",
    "            print(f\"[{name}] {path} call failed: {e}\")\n",
    "            return False\n",
    "\n",
    "    async def combine_rewards(self, info_dicts: List[Dict], overrides: dict | None = None) -> float:\n",
    "        \"\"\"\n",
    "        Combine amrfinder, prodigal, and plannotate responses into a single reward.\n",
    "        Scoring:\n",
    "          - Presence of ORI, AMR gene, MCS, promoter (weighted), each multiplied by percent identity if available.\n",
    "          - Small GC proximity bonus (around 55%) as a tie-breaker.\n",
    "        Extensible via self.require / self.weights / self.gc.\n",
    "        \"\"\"\n",
    "        require = dict(self.require)\n",
    "        weights = dict(self.weights)\n",
    "        gcconf  = dict(self.gc)\n",
    "    \n",
    "        # Merge per-example overrides if provided\n",
    "        if overrides:\n",
    "            if \"require\" in overrides: require.update(overrides[\"require\"] or {})\n",
    "            if \"weights\" in overrides: weights.update(overrides[\"weights\"] or {})\n",
    "            if \"gc\" in overrides:      gcconf.update(overrides[\"gc\"] or {})\n",
    "\n",
    "        # filter out failed calls (False) and normalize shape\n",
    "        records = [r for r in info_dicts if isinstance(r, dict) and r.get(\"status\") is not False]\n",
    "        by_name = {r.get(\"name\"): (r.get(\"reponse\") or {}) for r in records}\n",
    "    \n",
    "        amr = by_name.get(\"amrfinder\") or {}\n",
    "        prodigal = by_name.get(\"prodigal\") or {}\n",
    "        plannotate = by_name.get(\"plannotate\") or []\n",
    "    \n",
    "        # helpers\n",
    "        def _lc(s): return str(s or \"\").lower()\n",
    "        def _contains_any(text: str, needles) -> bool:\n",
    "            t = _lc(text)\n",
    "            return any(_lc(n) in t for n in (needles or []))\n",
    "        def _best_pident(entries) -> float:\n",
    "            \"\"\"Return best percent identity (0..1) among provided plannotate entries with 'pident'.\"\"\"\n",
    "            best = 0.0\n",
    "            for e in entries:\n",
    "                try:\n",
    "                    p = float(e.get(\"pident\", 100.0)) / 100.0\n",
    "                except Exception:\n",
    "                    p = 1.0\n",
    "                best = max(best, max(0.0, min(1.0, p)))\n",
    "            return best if best > 0 else 1.0  # default to 1.0 if none provided\n",
    "    \n",
    "        # ---- ORI / MCS / Promoter from plannotate ----\n",
    "        ori_present, mcs_present, prom_present = False, False, False\n",
    "        ori_pident, mcs_pident, prom_pident = 1.0, 1.0, 1.0\n",
    "    \n",
    "        if isinstance(plannotate, list):\n",
    "            # buckets\n",
    "            ori_entries, mcs_entries, prom_entries = [], [], []\n",
    "    \n",
    "            for feat in plannotate:\n",
    "                name = str(feat.get(\"Feature\") or \"\")\n",
    "                desc = str(feat.get(\"Description\") or \"\")\n",
    "                typ  = str(feat.get(\"Type\") or \"\")\n",
    "                text = f\"{name} {desc} {typ}\"\n",
    "    \n",
    "                # ORI\n",
    "                if self.require[\"ori\"] is None:\n",
    "                    if typ.lower() == \"rep_origin\" or _contains_any(text, [\"ori\", \"colE1\", \"pmb1\", \"pbr322\", \"puc\"]):\n",
    "                        ori_entries.append(feat)\n",
    "                else:\n",
    "                    if _contains_any(text, self.require[\"ori\"]):\n",
    "                        ori_entries.append(feat)\n",
    "    \n",
    "                # MCS\n",
    "                if self.require[\"mcs\"] is True:\n",
    "                    if _contains_any(text, [\"mcs\", \"multiple cloning site\"]):\n",
    "                        mcs_entries.append(feat)\n",
    "                elif isinstance(self.require[\"mcs\"], list):\n",
    "                    if _contains_any(text, self.require[\"mcs\"]):\n",
    "                        mcs_entries.append(feat)\n",
    "    \n",
    "                # Promoter\n",
    "                if self.require[\"promoter\"] is None:\n",
    "                    if typ.lower() == \"promoter\" or _contains_any(text, [\"promoter\"]):\n",
    "                        prom_entries.append(feat)\n",
    "                else:\n",
    "                    if _contains_any(text, self.require[\"promoter\"]):\n",
    "                        prom_entries.append(feat)\n",
    "\n",
    "            if ori_entries:\n",
    "                ori_present = True\n",
    "                ori_pident = _best_pident(ori_entries)\n",
    "            if mcs_entries:\n",
    "                mcs_present = True\n",
    "                mcs_pident = _best_pident(mcs_entries)\n",
    "            if prom_entries:\n",
    "                prom_present = True\n",
    "                prom_pident = _best_pident(prom_entries)\n",
    "    \n",
    "        # ---- AMR from amrfinder ----\n",
    "        amr_present, amr_pident = False, 1.0\n",
    "        if isinstance(amr, dict):\n",
    "            hits = amr.get(\"genes\", []) or []\n",
    "            candidate_hits = []\n",
    "            for g in hits:\n",
    "                cls = str(g.get(\"class\") or \"\")\n",
    "                sym = str(g.get(\"element_symbol\") or \"\")\n",
    "                nm  = str(g.get(\"element_name\") or \"\")\n",
    "                hay = f\"{cls} {sym} {nm}\"\n",
    "                if self.require[\"amr\"] is None or _contains_any(hay, self.require[\"amr\"]):\n",
    "                    candidate_hits.append(g)\n",
    "            if candidate_hits:\n",
    "                amr_present = True\n",
    "                # pick best identity among matching hits\n",
    "                best = 1.0\n",
    "                for g in candidate_hits:\n",
    "                    try:\n",
    "                        pid = float(g.get(\"percent_identity_to_reference\", 100.0)) / 100.0\n",
    "                    except Exception:\n",
    "                        pid = 1.0\n",
    "                    best = max(best, max(0.0, min(1.0, pid)))\n",
    "                amr_pident = best\n",
    "\n",
    "        # ---- main score (presence × weight × identity) ----\n",
    "        w = self.weights\n",
    "        main = 0.0\n",
    "        if ori_present:   main += w.get(\"ori\", 0.0) * float(ori_pident)\n",
    "        if amr_present:   main += w.get(\"amr\", 0.0) * float(amr_pident)\n",
    "        if mcs_present:   main += w.get(\"mcs\", 0.0) * float(mcs_pident)\n",
    "        if prom_present:  main += w.get(\"promoter\", 0.0) * float(prom_pident)\n",
    "        main = min(main, 1.0)  # keep things tidy\n",
    "    \n",
    "        # ---- GC tie-breaker from prodigal ----\n",
    "        gc_bonus = 0.0\n",
    "        if isinstance(prodigal, dict):\n",
    "            meta = prodigal.get(\"metadata\", {}) or {}\n",
    "            gc_raw = meta.get(\"model_gc_cont\") or meta.get(\"gc_cont\")\n",
    "            if gc_raw is not None:\n",
    "                try:\n",
    "                    s = str(gc_raw).strip().replace(\"%\", \"\")\n",
    "                    v = float(s)\n",
    "                    gc = v / 100.0 if \"%\" in str(gc_raw) or v > 1.0 else v\n",
    "                    target = float(self.gc[\"target\"])\n",
    "                    tol = max(1e-6, float(self.gc[\"tolerance\"]))\n",
    "                    dist = abs(gc - target)\n",
    "                    norm = max(0.0, 1.0 - (dist / tol))   # 1 at target, 0 at >= tolerance\n",
    "                    gc_bonus = float(self.gc[\"weight\"]) * norm\n",
    "                except Exception:\n",
    "                    gc_bonus = 0.0\n",
    "    \n",
    "        total = main + gc_bonus\n",
    "        return float(total)\n",
    "\n",
    "\n",
    "    async def _call(self, td: TensorDict) -> TensorDict:\n",
    "        # 1) extract text(s)\n",
    "        llm_texts: list[str]\n",
    "        if \"text\" in td.keys(True):\n",
    "            t = td[\"text\"]\n",
    "            llm_texts = [t if isinstance(t, str) else getattr(t, \"response\", str(t))]\n",
    "        elif \"query\" in td.keys(True):\n",
    "                q = td.get(\"query\")\n",
    "                # if query is a list (batch), use it as-is; else wrap\n",
    "                llm_texts = list(q) if hasattr(q, \"__iter__\") and not isinstance(q, (str, bytes)) else [q]\n",
    "        else:\n",
    "            td[\"reward\"] = torch.zeros(td.batch_size + (1,), dtype=torch.float32)\n",
    "            return td\n",
    "    \n",
    "        # 2) extract per-example overrides (align shape)\n",
    "        overrides = td.get(\"reward_params\", None)\n",
    "        if overrides is None or isinstance(overrides, dict):\n",
    "            overrides_list = [overrides] * len(llm_texts)\n",
    "        else:\n",
    "            overrides_list = list(overrides)\n",
    "            if len(overrides_list) != len(llm_texts):\n",
    "                # safe fallback\n",
    "                overrides_list = [None] * len(llm_texts)\n",
    "    \n",
    "        # 3) call endpoints per example (sequential or parallel)\n",
    "        rewards: list[float] = []\n",
    "        for text, ov in zip(llm_texts, overrides_list):\n",
    "            # hit the three endpoints for THIS example\n",
    "            results = await asyncio.gather(*[\n",
    "                self._post_text(cfg[\"path\"], cfg.get(\"params\", {}), text, cfg[\"name\"])\n",
    "                for cfg in self._endpoints\n",
    "            ])\n",
    "            # combine with per-example params\n",
    "            r = await self.combine_rewards(results, overrides=ov)\n",
    "            rewards.append(float(r))\n",
    "    \n",
    "        # 4) write back (vector or scalar)\n",
    "        out = torch.as_tensor(rewards, dtype=torch.float32)\n",
    "        # reshape to td batch\n",
    "        if out.ndim == 1 and out.numel() == td.numel():\n",
    "            out = out.view(td.batch_size + (1,))\n",
    "        else:\n",
    "            out = out.mean().view(td.batch_size + (1,))  # conservative fallback\n",
    "        td[\"reward\"] = out\n",
    "        return td\n",
    "\n",
    "\n",
    "    def transform_reward_spec(self, reward_spec: CompositeSpec) -> CompositeSpec:\n",
    "        reward_spec[\"reward\"] = Unbounded(shape=reward_spec.shape + (1,), dtype=torch.float32)\n",
    "        return reward_spec\n",
    "\n",
    "    async def aclose(self):\n",
    "        try:\n",
    "            await self.client.aclose()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    def __del__(self):\n",
    "        try:\n",
    "            if not self.client.is_closed:\n",
    "                loop = asyncio.get_event_loop()\n",
    "                if loop.is_running():\n",
    "                    loop.create_task(self.client.aclose())\n",
    "        except Exception:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "65dfd8d5-fb5a-4664-abf9-ecfade327e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plasmid = \"GGGCGAATTCGAGCTCGGTACCCGGGGATCCTCTAGAGTCGACCTGCAGGCATGCAAGCTTGAGTATTCTATAGTGTCACCTAAATAGCTTGGCGTAATCATGGTCATAGCTGTTTCCTGTGTGAAATTGTTATCCGCTCACAATTCCACACAACATACGAGCCGGAAGCATAAAGTGTAAAGCCTGGGGTGCCTAATGAGTGAGCTAACTCACATTAATTGCGTTGCGCTCACTGCCCGCTTTCCAGTCGGGAAACCTGTCGTGCCAGCTGCATTAATGAATCGGCCAACGCGCGGGGAGAGGCGGTTTGCGTATTGGGCGCTCTTCCGCTTCCTCGCTCACTGACTCGCTGCGCTCGGTCGTTCGGCTGCGGCGAGCGGTATCAGCTCACTCAAAGGCGGTAATACGGTTATCCACAGAATCAGGGGATAACGCAGGAAAGAACATGAATTAATTCTCATGTTTGACAGCTTATCATCGATTAGCTTTAATGCGGTAGTTTATCACAGTTAAATTGCTAACGCAGTCAGGCACCGTGTATGAAATCTAACAATGCGCTCATCGTCATCCTCGGCACCGTCACCCTGGATGCTGTAGGCATAGGCTTGGTTATGCCGGTACTGCCGGGCCTCTTGCGGGATATCGTCCATTCCGACAGCATCGCCAGTCACTATGGCGTGCTGCTAGCGCTATATGCGTTGATGCAATTTCTATGCGCACCCGTTCTCGGAGCACTGTCCGACCGCTTTGGCCGCCGCCCAGTCCTGCTCGCTTCGCTACTTGGAGCCACTATCGACTACGCGATCATGGCGACCACACCCGTCCTGTGGATTCTCTACGCCGGACGCATCGTGGCCGGCATCACCGGCGCCACAGGTGCGGTTGCTGGCGCCTATATCGCCGACATCACCGATGGGGAAGATCGGGCTCGCCACTTCGGGCTCATGAGCGCTTGTTTCGGCGTGGGTATGGTGGCAGGCCCCGTGGCCGGGGGACTGTTGGGCGCCATCTCCTTACATGCACCATTCCTTGCGGCGGCGGTGCTCAACGGCCTCAACCTACTACTGGGCTGCTTCCTAATGCAGGAGTCGCATAAGGGAGAGCGCCGACCGATGCCCTTGAGAGCCTTCAACCCAGTCAGCTCCTTCCGGTGGGCGCGGGGCATGACTATCGTCGCCGCACTTATGACTGTCTTCTTTATCATGCAACTCGTAGGACAGGTGCCGGCAGCGCTCTGGGTCATTTTCGGCGAGGACCGCTTTCGCTGGAGCGCGACGATGATCGGCCTGTCGCTTGCGGTATTCGGAATCTTGCACGCCCTCGCTCAAGCCTTCGTCACTGGTCCCGCCACCAAACGTTTCGGCGAGAAGCAGGCCATTATCGCCGGCATGGCGGCCGACGCGCTGGGCTACGTCTTGCTGGCGTTCGCGACGCGAGGCTGGATGGCCTTCCCCATTATGATTCTTCTCGCTTCCGGCGGCATCGGGATGCCCGCGTTGCAGGCCATGCTGTCCAGGCAGGTAGATGACGACCATCAGGGACAGCTTCAAGGATCGCTCGCGGCTCTTACCAGCCTAACTTCGATCACTGGACCGCTGATCGTCACGGCGATTTATGCCGCCTCGGCGAGCACATGGAACGGGTTGGCATGGATTGTAGGCGCCGCCCTATACCTTGTCTGCCTCCCCGCGTTGCGTCGCGGTGCATGGAGCCGGGCCACCTCGACCTGAATGGAAGCCGGCGGCACCTCGCTAACGGATTCACCACTCCAAGAATTGGAGCCAATCAATTCTTGCGGAGAACTGTGAATGCGCAAACCAACCCTTGGCAGAACATATCCATCGCGTCCGCCATCTCCAGCAGCCGCACGCGGCGCATCTCGGGCAGCGTTGGGTCCTGGCCACGGGTGCGCATGATCGTGCTCCTGTCGTTGAGGACCCGGCTAGGCTGGCGGGGTTGCCTTACTGGTTAGCAGAATGAATCACCGATACGCGAGCGAACGTGAAGCGACTGCTGCTGCAAAACGTCTGCGACCTGAGCAACAACATGAATGGTCTTCGGTTTCCGTGTTTCGTAAAGTCTGGAAACGCGGAAGTCAGCGCCCTGCACCATTATGTTCCGGATCTGCATCGCAGGATGCTGCTGGCTACCCTGTGGAACACCTACATCTGTATTAACGAAGCGCTGGCATTGACCCTGAGTGATTTTTCTCTGGTCCCGCCGCATCCATACCGCCAGTTGTTTACCCTCACAACGTTCCAGTAACCGGGCATGTTCATCATCAGTAACCCGTATCGTGAGCATCCTCTCTCGTTTCATCGGTATCATTACCCCCATGAACAGAAATTCCCCCTTACACGGAGGCATCAAGTGACCAAACAGGAAAAAACCGCCCTTAACATGGCCCGCTTTATCAGAAGCCAGACATTAACGCTTCTGGAGAAACTCAACGAGCTGGACGCGGATGAACAGGCAGACATCTGTGAATCGCTTCACGACCACGCTGATGAGCTTTACCGCAGCTGCCTCGCGCGTTTCGGTGATGACGGTGAAAACCTCTGACACATGCAGCTCCCGGAGACGGTCACAGCTTGTCTGTAAGCGGATGCCGGGAGCAGACAAGCCCGTCAGGGCGCGTCAGCGGGTGTTGGCGGGTGTCGGGGCGCAGCCATGACCCAGTCACGTAGCGATAGCGGAGTGTATACTGGCTTAACTATGCGGCATCAGAGCAGATTGTACTGAGAGTGCACCATATGCGGTGTGAAATACCGCACAGATGCGTAAGGAGAAAATACCGCATCAGGCGCTCTTCCGCTTCCTCGCTCACTGACTCGCTGCGCTCGGTCGTTCGGCTGCGGCGAGCGGTATCAGCTCACTCAAAGGCGGTAATACGGTTATCCACAGAATCAGGGGATAACGCAGGAAAGAACATGTGAGCAAAAGGCCAGCAAAAGGCCAGGAACCGTAAAAAGGCCGCGTTGCTGGCGTTTTTCCATAGGCTCCGCCCCCCTGACGAGCATCACAAAAATCGACGCTCAAGTCAGAGGTGGCGAAACCCGACAGGACTATAAAGATACCAGGCGTTTCCCCCTGGAAGCTCCCTCGTGCGCTCTCCTGTTCCGACCCTGCCGCTTACCGGATACCTGTCCGCCTTTCTCCCTTCGGGAAGCGTGGCGCTTTCTCATAGCTCACGCTGTAGGTATCTCAGTTCGGTGTAGGTCGTTCGCTCCAAGCTGGGCTGTGTGCACGAACCCCCCGTTCAGCCCGACCGCTGCGCCTTATCCGGTAACTATCGTCTTGAGTCCAACCCGGTAAGACACGACTTATCGCCACTGGCAGCAGCCACTGGTAACAGGATTAGCAGAGCGAGGTATGTAGGCGGTGCTACAGAGTTCTTGAAGTGGTGGCCTAACTACGGCTACACTAGAAGGACAGTATTTGGTATCTGCGCTCTGCTGAAGCCAGTTACCTTCGGAAAAAGAGTTGGTAGCTCTTGATCCGGCAAACAAACCACCGCTGGTAGCGGTGGTTTTTTTGTTTGCAAGCAGCAGATTACGCGCAGAAAAAAAGGATCTCAAGAAGATCCTTTGATCTTTTCTACGGGGTCTGACGCTCAGTGGAACGAAAACTCACGTTAAGGGATTTTGGTCATGAGATTATCAAAAAGGATCTTCACCTAGATCCTTTTAAATTAAAAATGAAGTTTTAAATCAATCTAAAGTATATATGAGTAAACTTTGGCTGACAGTTACCAATGCTTAATCAGTGAGGCACCTATCTCAGCGATCTGTCTATTTCGTTCATCCATAGTTGCCTGACTCCCCGTCGTGTAGATAACTACGATACGGGAGGGCTTACCATCTGGCCCCAGTGCTGCAATGATACCGCGAGACCCACGCTCACCGGCTCCAGATTTATCAGCAATAAACCAGCCAGCCGGAAGGGCCGAGCGCAGAAGTGGTCCTGCAACTTTATCCGCCTCCATCCAGTCTATTAATTGTTGCCGGGAAGCTAGAGTAAGTAGTTCGCCAGTTAATAGTTTGCGCAACGTTGTTGCCATTGCGGCATCGTGGTGTCACGCTCGTCGTTTGGTATGGCTTCATTCAGCTCCGGTTCCCAACGATCAAGGCGAGTTACATGATCCCCCATGTTGTGCAAAAAAGCGGTTAGCTCCTTCGGTCCTCCGATCGTTGTCAGAAGTAAGTTGGCCGCAGTGTTATCACTCATGGTTATGGCAGCACTGCATAATTCTCTTACTGTCATGCCATCCGTAAGATGCTTTTCTGTGACTGGTGAGTACTCAACCAAGTCATTCTGAGAATAGTGTATGCGGCGACCGAGTTGCTCTTGCCCGGCGTCAACACGGGATAATACCGCGCCACATAGCAGAACTTTAAAAGTGCTCATCATTGGAAAACGTTCTTCGGGGCGAAAACTCTCAAGGATCTTACCGCTGTTGAGATCCAGTTCGATGTAACCCACTCGTGCACCCAACTGATCTTCAGCATCTTTTACTTTCACCAGCGTTTCTGGGTGAGCAAAAACAGGAAGGCAAAATGCCGCAAAAAAGGGAATAAGGGCGACACGGAAATGTTGAATACTCATACTCTTCCTTTTTCAATATTATTGAAGCATTTATCAGGGTTATTGTCTCATGAGCGGATACATATTTGAATGTATTTAGAAAAATAAACAAATAGGGGTTCCGCGCACATTTCCCCGAAAAGTGCCACCTGACGTCTAAGAAACCATTATTATCATGACATTAACCTATAAAAATAGGCGTATCACGAGGCCCTTTCGTCTCGCGCGTTTCGGTGATGACGGTGAAAACCTCTGACACATGCAGCTCCCGGAGACGGTCACAGCTTGTCTGTAAGCGGATGCCGGGAGCAGACAAGCCCGTCAGGGCGCGTCAGCGGGTGTTGGCGGGTGTCGGGGCTGGCTTAACTATGCGGCATCAGAGCAGATTGTACTGAGAGTGCACCATATGCGGTGTGAAATACCGCACAGATGCGTAAGGAGAAAATACCGCATCAGGCGAAATTGTAAACGTTAATATTTTGTTAAAATTCGCGTTAAATATTTGTTAAATCAGCTCATTTTTTAACCAATAGGCCGAAATCGGCAAAATCCCTTATAAATCAAAAGAATAGACCGAGATAGGGTTGAGTGTTGTTCCAGTTTGGAACAAGAGTCCACTATTAAAGAACGTGGACTCCAACGTCAAAGGGCGAAAAACCGTCTATCAGGGCGATGGCCCACTACGTGAACCATCACCCAAATCAAGTTTTTTGCGGTCGAGGTGCCGTAAAGCTCTAAATCGGAACCCTAAAGGGAGCCCCCGATTTAGAGCTTGACGGGGAAAGCCGGCGAACGTGGCGAGAAAGGAAGGGAAGAAAGCGAAAGGAGCGGGCGCTAGGGCGCTGGCAAGTGTAGCGGTCACGCTGCGCGTAACCACCACACCCGCCGCGCTTAATGCGCCGCTACAGGGCGCGTCCATTCGCCATTCAGGCTGCGCAACTGTTGGGAAGGGCGATCGGTGCGGGCCTCTTCGCTATTACGCCAGCTGGCGAAAGGGGGATGTGCTGCAAGGCGATTAAGTTGGGTAACGCCAGGGTTTTCCCAGTCACGACGTTGTAAAACGACGGCCAGTGAATTGTAATACGACTCACTATA\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a7ac9f0-eb3f-4938-95cd-1b2e432adc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: tensor([[1.0435]])\n"
     ]
    }
   ],
   "source": [
    "td = TensorDict({}, batch_size=(1,))\n",
    "class DummyText:\n",
    "    def __init__(self, response: str):\n",
    "        self.response = response\n",
    "\n",
    "td['text'] = test_plasmid\n",
    "\n",
    "rt = RewardTransform(\"http://server:8080\")\n",
    "\n",
    "scored = await rt._call(td)\n",
    "print(\"Reward:\", scored[\"reward\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "affe553e-491f-4831-a691-44471d1145fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = env.append_transform(RewardTransform(\"http://server:8080\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "311943a8-6f9e-49fd-b7b0-585480693f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultQueryOnReset(Transform):\n",
    "    def __init__(self, default_query: list[str]):\n",
    "        super().__init__()\n",
    "        self.default_query = default_query\n",
    "\n",
    "    # This is the hook TransformedEnv invokes before calling base_env._reset(...)\n",
    "    def _reset_env_preprocess(self, tensordict: TensorDict | None) -> TensorDict:\n",
    "        if tensordict is None or (\"query\" not in tensordict.keys(True)):\n",
    "            b = (len(self.default_query),)\n",
    "            tensordict = TensorDict({\"query\": self.default_query}, batch_size=b)\n",
    "        return tensordict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ffa96310-f2ff-40a1-a8ad-eacfd543d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this with the GRP starter\n",
    "env = env.append_transform(DefaultQueryOnReset([\"AATG\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1769442b-e16d-46a1-a9b4-3958ec57ad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.modules.llm import TransformersWrapper\n",
    "from torchrl.collectors.llm import LLMCollector\n",
    "from torchrl.objectives.llm import GRPOLoss\n",
    "\n",
    "policy = TransformersWrapper(\n",
    "    model=model,          # \"McClain/plasmidgpt-addgene-gpt2\"\n",
    "    tokenizer=tokenizer,\n",
    "    input_mode=\"text\",\n",
    "    return_log_probs=True,\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c504e551-6388-470c-ba4c-47d5cf1a0fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = TransformersWrapper(\n",
    "    model=model,              # or a separate ref checkpoint\n",
    "    tokenizer=tokenizer,\n",
    "    input_mode=\"text\",\n",
    "    return_log_probs=True,\n",
    "    #freeze_model=True\n",
    ").eval()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ebf100e1-5dd0-46d0-af97-3743c3c63c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "collector = LLMCollector(\n",
    "    policy=policy,\n",
    "    env=env,\n",
    "    dialog_turns_per_batch=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a502477-eb3d-4478-b1a1-31f1e122caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.data.replay_buffers import ReplayBuffer\n",
    "from torchrl.data.replay_buffers.storages import ListStorage\n",
    "from torchrl.objectives.llm import MCAdvantage\n",
    "\n",
    "# Keep K responses per (same) prompt before computing advantage\n",
    "K = 4\n",
    "rb = ReplayBuffer(\n",
    "    storage=ListStorage(1024),\n",
    "    transform=MCAdvantage(grpo_size=K)  # writes \"advantage\" into items once K complete trajs exist\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f2fe750-b00b-480d-bc94-d720e0af92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_module = GRPOLoss(\n",
    "    actor_network=policy,\n",
    "    # You can add KL-to-reference regularization if desired:\n",
    "    kl_to_ref_coeff=0.01,\n",
    "    masking_strategy=\"sft\",   # single-turn: only response tokens; multi-turn: \"rlhf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "400f578e-8d70-47ca-bf44-090403177035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mcclain/.venv/lib/python3.11/site-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'coroutine' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m num_iters = \u001b[32m200\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m it \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_iters):\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# 1) Generate one dialog turn (the env handles reset() via your transform)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcollector\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      7\u001b[39m \n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# --- make reward shape broadcastable: (*bsz, 1, 1) ---\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[43mr\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreward\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mcclain/.venv/lib/python3.11/site-packages/torchrl/collectors/collectors.py:341\u001b[39m, in \u001b[36mDataCollectorBase.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[TensorDictBase]:\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iterator()\n\u001b[32m    342\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    343\u001b[39m         \u001b[38;5;28mself\u001b[39m.shutdown()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mcclain/.venv/lib/python3.11/site-packages/torchrl/collectors/collectors.py:1256\u001b[39m, in \u001b[36mSyncDataCollector.iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose:\n\u001b[32m   1255\u001b[39m     torchrl_logger.info(\u001b[33m\"\u001b[39m\u001b[33mCollector: rollout.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1256\u001b[39m tensordict_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1257\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1258\u001b[39m     \u001b[38;5;66;03m# if a replay buffer is passed and self.extend_buffer=False, there is no tensordict_out\u001b[39;00m\n\u001b[32m   1259\u001b[39m     \u001b[38;5;66;03m#  frames are updated within the rollout function\u001b[39;00m\n\u001b[32m   1260\u001b[39m     torchrl_logger.info(\u001b[33m\"\u001b[39m\u001b[33mCollector: No tensordict_out. Yielding.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mcclain/.venv/lib/python3.11/site-packages/torchrl/collectors/llm/base.py:314\u001b[39m, in \u001b[36mLLMCollector._rollout_all\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    310\u001b[39m     torchrl_logger.info(\n\u001b[32m    311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mLLMCollector: Collected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollected_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m steps over \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.dialog_turns_per_batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requested.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    312\u001b[39m     )\n\u001b[32m    313\u001b[39m env_input = \u001b[38;5;28mself\u001b[39m.policy(policy_input)\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m env_output, env_next_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep_and_maybe_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[38;5;66;03m# carry over collector data without messing up devices\u001b[39;00m\n\u001b[32m    317\u001b[39m collector_data = env_output.get(\u001b[33m\"\u001b[39m\u001b[33mcollector\u001b[39m\u001b[33m\"\u001b[39m).copy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mcclain/.venv/lib/python3.11/site-packages/torchrl/envs/common.py:3655\u001b[39m, in \u001b[36mEnvBase.step_and_maybe_reset\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   3653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tensordict.device != \u001b[38;5;28mself\u001b[39m.device:\n\u001b[32m   3654\u001b[39m     tensordict = tensordict.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m-> \u001b[39m\u001b[32m3655\u001b[39m tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3656\u001b[39m \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[32m   3657\u001b[39m \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[32m   3658\u001b[39m tensordict_ = \u001b[38;5;28mself\u001b[39m._step_mdp(tensordict)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mcclain/.venv/lib/python3.11/site-packages/torchrl/envs/common.py:2102\u001b[39m, in \u001b[36mEnvBase.step\u001b[39m\u001b[34m(self, tensordict)\u001b[39m\n\u001b[32m   2100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_tensordict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2101\u001b[39m     next_tensordict = \u001b[38;5;28mself\u001b[39m._step(tensordict)\n\u001b[32m-> \u001b[39m\u001b[32m2102\u001b[39m     next_tensordict = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_proc_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_tensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2104\u001b[39m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[32m   2105\u001b[39m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[32m   2106\u001b[39m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n\u001b[32m   2107\u001b[39m     next_tensordict.update(\n\u001b[32m   2108\u001b[39m         next_preset.exclude(*next_tensordict.keys(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m   2109\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mcclain/.venv/lib/python3.11/site-packages/torchrl/envs/common.py:2204\u001b[39m, in \u001b[36mEnvBase._step_proc_data\u001b[39m\u001b[34m(self, next_tensordict_out)\u001b[39m\n\u001b[32m   2201\u001b[39m batch_size = \u001b[38;5;28mself\u001b[39m.batch_size\n\u001b[32m   2202\u001b[39m dims = \u001b[38;5;28mlen\u001b[39m(batch_size)\n\u001b[32m   2203\u001b[39m leading_batch_size = (\n\u001b[32m-> \u001b[39m\u001b[32m2204\u001b[39m     \u001b[43mnext_tensordict_out\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_size\u001b[49m[:-dims]\n\u001b[32m   2205\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dims\n\u001b[32m   2206\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m next_tensordict_out.shape\n\u001b[32m   2207\u001b[39m )\n\u001b[32m   2208\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m reward_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reward_keys:\n\u001b[32m   2209\u001b[39m     expected_reward_shape = torch.Size(\n\u001b[32m   2210\u001b[39m         [\n\u001b[32m   2211\u001b[39m             *leading_batch_size,\n\u001b[32m   2212\u001b[39m             *\u001b[38;5;28mself\u001b[39m.output_spec[\u001b[33m\"\u001b[39m\u001b[33mfull_reward_spec\u001b[39m\u001b[33m\"\u001b[39m][reward_key].shape,\n\u001b[32m   2213\u001b[39m         ]\n\u001b[32m   2214\u001b[39m     )\n",
      "\u001b[31mAttributeError\u001b[39m: 'coroutine' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "num_iters = 200\n",
    "for it in range(num_iters):\n",
    "    # 1) Generate one dialog turn (the env handles reset() via your transform)\n",
    "    for it, td in enumerate(collector):\n",
    "    \n",
    "        # --- make reward shape broadcastable: (*bsz, 1, 1) ---\n",
    "        if \"reward\" in td.keys():\n",
    "            r = td.get(\"reward\")\n",
    "            if r.ndim == len(td.batch_size):          # e.g., (B,)\n",
    "                r = r.unsqueeze(-1).unsqueeze(-1)     # -> (B,1,1)\n",
    "            elif r.ndim == len(td.batch_size) + 1:    # e.g., (B,1)\n",
    "                r = r.unsqueeze(-1)                   # -> (B,1,1)\n",
    "            td.set(\"reward\", r)\n",
    "    \n",
    "        # 2) Push to RB → MCAdvantage will fill \"advantage\" once it has K trajs for the same prompt\n",
    "        rb.add(td)\n",
    "    \n",
    "        # Not every iter will have advantage ready; skip until MCAdvantage emits it\n",
    "        if \"advantage\" not in td.keys():\n",
    "            if it % 20 == 0:\n",
    "                print(f\"[it {it}] waiting for groups (K={K}) to fill…\")\n",
    "            continue\n",
    "    \n",
    "        # 3) Compute GRPO loss and update\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        loss_td = loss_module(td)          # produces \"loss/*\" scalars\n",
    "        loss = sum(v for k, v in loss_td.items() if k.startswith(\"loss\"))\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "        # 4) Basic logging\n",
    "        avg_r = float(td.get(\"reward\").mean().item()) if \"reward\" in td.keys() else math.nan\n",
    "        print(f\"[it {it}] loss={loss.item():.4f}  avg_reward={avg_r:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3bb2c-0aa9-4af7-9b03-ebf020bc746f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
