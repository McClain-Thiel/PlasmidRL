_wandb:
    value:
        cli_version: 0.21.0
        e:
            ismvh2dxa52rnxefldi2bcez8se17nq3:
                args:
                    - --dataset-config
                    - sft/train_evo2.yaml
                    - --devices
                    - "1"
                    - --num-nodes
                    - "1"
                    - --seq-length
                    - "2048"
                    - --model-size
                    - 1b
                    - --micro-batch-size
                    - "1"
                    - --grad-acc-batches
                    - "16"
                    - --tensor-parallel-size
                    - "1"
                    - --pipeline-model-parallel-size
                    - "1"
                    - --context-parallel-size
                    - "1"
                    - --workers
                    - "4"
                    - --activation-checkpoint-recompute-num-layers
                    - "9999"
                    - --fp8
                    - --ckpt-dir
                    - /mcclain/models/nemo2_evo2_1b_8k
                    - --wandb-entity
                    - mcclain
                    - --wandb-project
                    - plasmidrl
                    - --wandb-tags
                    - evo2
                    - plasmidrl
                    - sft
                    - --wandb-group
                    - ""
                    - --wandb-job-type
                    - finetune
                    - --wandb-run-name
                    - ""
                cpu_count: 4
                cpu_count_logical: 8
                cudaVersion: "12.9"
                disk:
                    /:
                        total: "1081101176832"
                        used: "119637266432"
                email: mcclain.thiel@gmail.com
                executable: /usr/bin/python
                git:
                    remote: https://github.com/McClain-Thiel/PlasmidRL.git
                gpu: Tesla T4
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Turing
                      cudaCores: 2560
                      memoryTotal: "16106127360"
                      name: Tesla T4
                      uuid: GPU-74b9bfa5-ed01-0f80-8fe0-37b0cb9e438e
                host: 88c1daa8f0dd
                memory:
                    total: "33263779840"
                os: Linux-6.8.0-1036-aws-x86_64-with-glibc2.39
                program: -m bionemo.evo2.run.train
                python: CPython 3.12.3
                root: results/evo2
                startedAt: "2025-09-17T11:52:18.080533Z"
                writerId: ismvh2dxa52rnxefldi2bcez8se17nq3
        m:
            - "1": trainer/global_step
              "6":
                - 3
              "7": []
            - "2": '*'
              "5": 1
              "6":
                - 1
              "7": []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 5
                - 9
                - 11
                - 41
                - 49
                - 50
                - 51
                - 53
                - 71
                - 98
                - 103
                - 106
            "2":
                - 1
                - 5
                - 9
                - 11
                - 41
                - 49
                - 50
                - 51
                - 53
                - 71
                - 98
                - 103
                - 106
            "3":
                - 7
                - 13
                - 15
                - 66
            "4": 3.12.3
            "5": 0.21.0
            "6": 4.51.3
            "12": 0.21.0
            "13": linux-x86_64
