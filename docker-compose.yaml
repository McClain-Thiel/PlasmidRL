
x-common: &common
  build:
    context: .
    dockerfile: docker/grpo.Dockerfile
  working_dir: /mcclain
  user: "${UID:-1000}:${GID:-1000}"
  env_file:
    - .env
  environment:
    # GPU selection and torch DDP configs
    - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES}
    - NCCL_P2P_DISABLE=0
    - NCCL_IB_DISABLE=0
    - NCCL_SOCKET_IFNAME=^lo,docker0
    # Logging / caching
    - LOG_DIR=/mcclain/logs
    - CHECKPOINT_DIR=/mcclain/checkpoints
    - HF_HOME=/mcclain/.cache/huggingface
    - HF_DATASETS_CACHE=/mcclain/.cache/huggingface/datasets
    - UV_CACHE_DIR=/mcclain/.cache/uv
    - INFORMATICS_SERVER_URL=${INFORMATICS_SERVER_URL:-http://server:8080}
    # Authentication tokens (from .env file)
    - HF_TOKEN=${HF_TOKEN}
    - WANDB_API_KEY=${WANDB_API_KEY}
    - ADVANTAGE_VERBOSE=true
    - LOG_LEVEL=DEBUG
  volumes:
    # project code and notebooks (editable)
    - ./:/mcclain
    # persistent outputs
    - ./checkpoints:/mcclain/checkpoints
    - ./logs:/mcclain/logs
    - ./notebooks:/mcclain/notebooks
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
  restart: unless-stopped

services:
  # Interactive shell for debugging
  dev:
    <<: *common
    command: bash
    tty: true

  # --- Long-running GRPO job (GRPO RL training) ---
  grpo:
    <<: *common
    # Run the GRPO RL training script
    command: >
      bash -lc "
        echo 'Waiting for server to be ready...' &&
        sleep 10 &&
        echo 'Starting GRPO RL training...' &&
        uv sync --frozen &&
        uv run python -m src.runners.rl_env
      "
    environment:
      - NPROC_PER_NODE=${NPROC_PER_NODE:-1}
      - RESUME=${RESUME:-false}
    depends_on:
      server:
        condition: service_healthy
    profiles: ["jobs"]

  verl:
    build:
      context: .
      dockerfile: docker/verl.Dockerfile
    working_dir: /workspace/verl
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES}
      - NCCL_P2P_DISABLE=0
      - NCCL_IB_DISABLE=0
      - NCCL_SOCKET_IFNAME=^lo,docker0
      - VLLM_USE_V1=1
      - HF_TOKEN=${HF_TOKEN}
      - WANDB_API_KEY=${WANDB_API_KEY}
    volumes:
      - ./data:/workspace/verl/data
      - ./checkpoints:/workspace/verl/checkpoints
      - ./logs:/workspace/verl/logs
      - ./config/verl_ppo.yaml:/opt/verl/verl/trainer/config/verl_ppo.yaml:ro
      - ./src:/workspace/verl/src:ro
    restart: unless-stopped
    command: >
      bash -c "
        echo 'Waiting for server to be ready...' &&
        sleep 10 &&
        echo 'Starting VERL RL training (naive LLaMA from HF)...' &&
        python3 -m verl.trainer.main_ppo --config-name verl_naive_ppo
      "
    depends_on:
      server:
        condition: service_healthy
    profiles: ["jobs"]



  # Optional: evaluation job
  eval:
    <<: *common
    command: >
      bash -lc "
        uv sync --frozen &&
        uv run -m src.cli eval
          --config config/eval.yaml
          --checkpoint ${CHECKPOINT_DIR}/latest.pt
          --log-dir ${LOG_DIR}
      "
    depends_on:
      server:
        condition: service_healthy
    profiles: ["jobs"]

  # FastAPI backend required by train/eval
  server:
    build:
      context: ${PLASMID_SERVER_PATH:-../Plasmid-Informatics-Server}
    restart: unless-stopped
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 15s
      timeout: 60s
      retries: 5
      start_period: 90s

  # Optional: TensorBoard
  tensorboard:
    <<: *common
    command: >
      bash -lc "uv run  tensorboard.main --logdir ${LOG_DIR} --host 0.0.0.0 --port 6006"
    ports:
      - "6006:6006"
    profiles: ["viz"]

  # Optional: notebook
  notebook:
    <<: *common
    command: >
      bash -lc "cd /mcclain && uv sync --python python3.11 && uv run python -m jupyterlab --no-browser --ServerApp.ip=0.0.0.0 --ServerApp.token='' --port 8888"
    ports:
      - "8888:8888"
    depends_on:
      server:
        condition: service_healthy
    profiles: ["viz"]


